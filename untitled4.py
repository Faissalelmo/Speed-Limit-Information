# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k1DzKsnP3ALw3S6xijoqxj6hlH3FIRQC
"""

from google.colab import drive
drive.mount('/content/drive')

"""## tests"""

!pip install numpy==1.24.4
!pip install imgaug

import os
import shutil
import yaml
import cv2
import numpy as np
from sklearn.model_selection import train_test_split
from collections import Counter
import imgaug.augmenters as iaa
from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage

def detect_panel(image):
    """D√©tecte automatiquement un panneau sur une image et retourne bbox normalis√©e."""
    h, w = image.shape[:2]
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray = cv2.medianBlur(gray, 5)

    circles = cv2.HoughCircles(
        gray, cv2.HOUGH_GRADIENT, dp=1.2, minDist=30,
        param1=50, param2=30, minRadius=10, maxRadius=300
    )

    if circles is not None:
        circles = np.uint16(np.around(circles))
        x, y, r = circles[0][0]  # Prend juste le premier cercle trouv√©
        x_center = x / w
        y_center = y / h
        width = (2 * r) / w
        height = (2 * r) / h
        return [x_center, y_center, width, height]
    else:
        # Pas de panneau d√©tect√©, retourne None
        return None

def augment_image(image, bbox):
    augmenter = iaa.Sequential([
        iaa.Affine(rotate=(-10, 10)),
        iaa.AddToBrightness((-30, 30)),
        iaa.GaussianBlur(sigma=(0, 0.5)),
        iaa.Multiply((0.8, 1.2))
    ])

    h, w = image.shape[:2]
    x_center, y_center, width, height = bbox
    x1 = int((x_center - width/2) * w)
    y1 = int((y_center - height/2) * h)
    x2 = int((x_center + width/2) * w)
    y2 = int((y_center + height/2) * h)

    bbs = BoundingBoxesOnImage([BoundingBox(x1=x1, y1=y1, x2=x2, y2=y2)], shape=image.shape)

    image_aug, bbs_aug = augmenter(image=image, bounding_boxes=bbs)
    bb_aug = bbs_aug.bounding_boxes[0]

    x_center = (bb_aug.x1 + bb_aug.x2) / (2 * w)
    y_center = (bb_aug.y1 + bb_aug.y2) / (2 * h)
    width = (bb_aug.x2 - bb_aug.x1) / w
    height = (bb_aug.y2 - bb_aug.y1) / h

    return image_aug, [
        np.clip(x_center, 0, 1),
        np.clip(y_center, 0, 1),
        np.clip(width, 0, 1),
        np.clip(height, 0, 1)
    ]

def prepare_dataset(source_dir, output_dir, min_samples_per_class=100):
    images_dir = os.path.join(output_dir, "images")
    labels_dir = os.path.join(output_dir, "labels")
    os.makedirs(images_dir, exist_ok=True)
    os.makedirs(labels_dir, exist_ok=True)

    class_folders = sorted([f for f in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, f))])
    class_map = {folder: idx for idx, folder in enumerate(class_folders)}

    print(" Mapping des classes :")
    for name, idx in class_map.items():
        print(f"{idx}: {name}")

    class_counts = Counter()

    for class_name, class_id in class_map.items():
        class_path = os.path.join(source_dir, class_name)
        images = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

        if not images:
            print(f" Pas d'images pour la classe {class_name}")
            continue

        for img_name in images:
            src_img_path = os.path.join(class_path, img_name)
            dst_img_name = f"{class_name}_{img_name}"
            dst_img_path = os.path.join(images_dir, dst_img_name)
            dst_lbl_path = os.path.join(labels_dir, os.path.splitext(dst_img_name)[0] + '.txt')

            image = cv2.imread(src_img_path)
            if image is None:
                print(f" Impossible de lire l'image : {src_img_path}")
                continue

            bbox = detect_panel(image)
            shutil.copyfile(src_img_path, dst_img_path)

            if bbox is None:
              print(f" Aucun panneau d√©tect√© dans {img_name}, labelis√© en speed_limit_unknown")
              # ID de la classe "speed_limit_unknown" (par exemple 24)
              unknown_class_id = 24
              # BBox couvrant tout l'image (ou adapte selon ton besoin)
              x_center, y_center, width, height = 0.67885435789864, 0.4578875324799, 1.0, 1.0
              with open(dst_lbl_path, 'w') as f:
                f.write(f"{unknown_class_id} {x_center} {y_center} {width} {height}\n")
            else:
              with open(dst_lbl_path, 'w') as f:
                f.write(f"{class_id} {bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]}\n")
              class_counts[class_id] += 1

            class_counts[class_id] += 1

        # Data Augmentation si pas assez d'images
        if class_counts[class_id] < min_samples_per_class:
            needed = min_samples_per_class - class_counts[class_id]
            print(f"üîÑ G√©n√©ration de {needed} augmentations pour {class_name}")
            for i in range(needed):
                src_img = np.random.choice(images)
                src_img_path = os.path.join(class_path, src_img)
                image = cv2.imread(src_img_path)
                if image is None:
                    continue
                bbox = detect_panel(image)
                if bbox is None:
                    continue
                aug_image, aug_bbox = augment_image(image, bbox)
                aug_img_name = f"{class_name}_aug_{i}_{src_img}"
                cv2.imwrite(os.path.join(images_dir, aug_img_name), aug_image)
                with open(os.path.join(labels_dir, f"{os.path.splitext(aug_img_name)[0]}.txt"), 'w') as f:
                    f.write(f"{class_id} {aug_bbox[0]} {aug_bbox[1]} {aug_bbox[2]} {aug_bbox[3]}\n")
                class_counts[class_id] += 1

    # Cr√©ation des splits Train / Val
    all_images = [img for img in os.listdir(images_dir)]
    all_labels = [int(open(os.path.join(labels_dir, os.path.splitext(img)[0] + '.txt')).readline().split()[0]) for img in all_images]

    train_imgs, val_imgs = train_test_split(all_images, test_size=0.2, stratify=all_labels, random_state=42)

    for split in ['train', 'val']:
        for folder in ['images', 'labels']:
            os.makedirs(os.path.join(output_dir, split, folder), exist_ok=True)

    for img_name in train_imgs:
        shutil.copy(os.path.join(images_dir, img_name), os.path.join(output_dir, 'train', 'images', img_name))
        shutil.copy(os.path.join(labels_dir, os.path.splitext(img_name)[0] + '.txt'), os.path.join(output_dir, 'train', 'labels', os.path.splitext(img_name)[0] + '.txt'))

    for img_name in val_imgs:
        shutil.copy(os.path.join(images_dir, img_name), os.path.join(output_dir, 'val', 'images', img_name))
        shutil.copy(os.path.join(labels_dir, os.path.splitext(img_name)[0] + '.txt'), os.path.join(output_dir, 'val', 'labels', os.path.splitext(img_name)[0] + '.txt'))

if __name__ == "__main__":
    source_dir = "/content/drive/MyDrive/sli1/database"  # Dossier contenant les dossiers par classe
    output_dir = "/content/drive/MyDrive/sli1/Fai"        # Dossier o√π sauvegarder dataset YOLO
    min_samples = 100

    prepare_dataset(source_dir, output_dir, min_samples)

"""## ex1"""

import os
import shutil
import yaml
import cv2
import numpy as np
from sklearn.model_selection import train_test_split
from collections import Counter
import imgaug.augmenters as iaa
from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage

def augment_image(image, bbox):
    """Applique data augmentation √† une image et ajuste les bounding boxes"""
    augmenter = iaa.Sequential([
        iaa.Affine(rotate=(-10, 10)),
        iaa.AddToBrightness((-30, 30)),
        iaa.GaussianBlur(sigma=(0, 0.5)),
        iaa.Multiply((0.8, 1.2))
    ])

    # Convertir bbox YOLO en format (x1, y1, x2, y2)
    h, w = image.shape[:2]
    x_center, y_center, width, height = bbox
    x1 = int((x_center - width/2) * w)
    y1 = int((y_center - height/2) * h)
    x2 = int((x_center + width/2) * w)
    y2 = int((y_center + height/2) * h)

    # Cr√©er un objet BoundingBoxesOnImage
    bbs = BoundingBoxesOnImage([
        BoundingBox(x1=x1, y1=y1, x2=x2, y2=y2)
    ], shape=image.shape)

    # Appliquer l'augmentation
    image_aug, bbs_aug = augmenter(image=image, bounding_boxes=bbs)

    # R√©cup√©rer la bbox augment√©e
    bb_aug = bbs_aug.bounding_boxes[0]

    # Reconvertir en format YOLO
    x_center = (bb_aug.x1 + bb_aug.x2) / (2 * w)
    y_center = (bb_aug.y1 + bb_aug.y2) / (2 * h)
    width = (bb_aug.x2 - bb_aug.x1) / w
    height = (bb_aug.y2 - bb_aug.y1) / h

    # S'assurer que les coordonn√©es sont dans les limites [0, 1]
    x_center = np.clip(x_center, 0, 1)
    y_center = np.clip(y_center, 0, 1)
    width = np.clip(width, 0, 1)
    height = np.clip(height, 0, 1)

    return image_aug, [x_center, y_center, width, height]

def prepare_dataset(source_dir, output_dir, min_samples_per_class=100):
    """Pr√©pare le dataset avec √©quilibrage des classes"""
    # 1. Cr√©ation des dossiers
    images_dir = os.path.join(output_dir, "images")
    labels_dir = os.path.join(output_dir, "labels")
    os.makedirs(images_dir, exist_ok=True)
    os.makedirs(labels_dir, exist_ok=True)

    # 2. Mapping des classes
    class_folders = sorted([f for f in os.listdir(source_dir)
                          if os.path.isdir(os.path.join(source_dir, f))])
    class_map = {folder: idx for idx, folder in enumerate(class_folders)}

    print("‚úÖ Mapping des classes :")
    for name, idx in class_map.items():
        print(f"{idx}: {name}")

    # 3. Copie et augmentation des donn√©es
    class_counts = Counter()

    for class_name, class_id in class_map.items():
        class_path = os.path.join(source_dir, class_name)
        if not os.path.isdir(class_path):
            continue

        print(f"\nTraitement de la classe {class_name} (ID: {class_id})")

        # Copier les images originales
        images = [f for f in os.listdir(class_path)
                 if f.lower().endswith(('.jpg', '.png', '.jpeg'))]

        if not images:
            print(f"‚ö†Ô∏è Aucune image trouv√©e pour la classe {class_name}")
            continue

        for img_name in images:
            src_img_path = os.path.join(class_path, img_name)
            dst_img_name = f"{class_name}_{img_name}"
            dst_img_path = os.path.join(images_dir, dst_img_name)
            dst_lbl_path = os.path.join(labels_dir, os.path.splitext(dst_img_name)[0] + ".txt")

            try:
                shutil.copyfile(src_img_path, dst_img_path)

                # Cr√©er l'annotation
                with open(dst_lbl_path, 'w') as f:
                    f.write(f"{class_id} 0.5 0.5 0.3 0.3\n")

                class_counts[class_id] += 1
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur lors du traitement de {img_name}: {str(e)}")

        # Augmentation des donn√©es si n√©cessaire
        if class_counts[class_id] < min_samples_per_class:
            needed = min_samples_per_class - class_counts[class_id]
            print(f"Augmentation de {needed} images pour la classe {class_name}")

            for i in range(needed):
                try:
                    # S√©lectionner une image al√©atoire de la classe
                    src_img = np.random.choice(images)
                    src_img_path = os.path.join(class_path, src_img)

                    # Lire l'image
                    image = cv2.imread(src_img_path)
                    if image is None:
                        print(f"‚ö†Ô∏è Impossible de lire l'image {src_img}")
                        continue

                    # Augmenter l'image
                    aug_image, aug_bbox = augment_image(image, [0.5, 0.5, 0.3, 0.3])

                    # Sauvegarder l'image augment√©e
                    aug_name = f"{class_name}_aug_{i}_{src_img}"
                    cv2.imwrite(os.path.join(images_dir, aug_name), aug_image)

                    # Sauvegarder l'annotation
                    with open(os.path.join(labels_dir, f"{os.path.splitext(aug_name)[0]}.txt"), 'w') as f:
                        f.write(f"{class_id} {aug_bbox[0]:.6f} {aug_bbox[1]:.6f} {aug_bbox[2]:.6f} {aug_bbox[3]:.6f}\n")

                    class_counts[class_id] += 1
                except Exception as e:
                    print(f"‚ö†Ô∏è Erreur lors de l'augmentation: {str(e)}")
                    continue

    # 4. Split stratifi√© train/val
    all_images = []
    for img_name in os.listdir(images_dir):
        try:
            label_path = os.path.join(labels_dir, os.path.splitext(img_name)[0] + '.txt')
            if os.path.exists(label_path):
                with open(label_path) as f:
                    class_id = int(f.readline().split()[0])
                    all_images.append((img_name, class_id))
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors de la lecture du label pour {img_name}: {str(e)}")

    if not all_images:
        raise ValueError("Aucune image valide trouv√©e pour le split train/val")

    X = [img[0] for img in all_images]
    y = [img[1] for img in all_images]

    train_imgs, val_imgs, train_labels, val_labels = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    # 5. Cr√©ation structure train/val
    for split in ['train', 'val']:
        for folder in ['images', 'labels']:
            os.makedirs(os.path.join(output_dir, split, folder), exist_ok=True)

    # 6. Distribution des fichiers
    for img, split_name in [(img, 'train') for img in train_imgs] + [(img, 'val') for img in val_imgs]:
        try:
            label = os.path.splitext(img)[0] + ".txt"
            shutil.copy(os.path.join(images_dir, img),
                       os.path.join(output_dir, split_name, "images", img))
            shutil.copy(os.path.join(labels_dir, label),
                       os.path.join(output_dir, split_name, "labels", label))
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur lors de la copie de {img}: {str(e)}")

    # 7. Cr√©ation dataset.yaml
    dataset_yaml = {
        'path': output_dir,
        'train': 'train/images',
        'val': 'val/images',
        'nc': len(class_map),
        'names': class_folders
    }

    yaml_path = os.path.join(output_dir, 'dataset.yaml')
    with open(yaml_path, 'w') as f:
        yaml.dump(dataset_yaml, f, sort_keys=False)

    # 8. Afficher les statistiques finales
    print("\nüìä Distribution finale des classes:")
    for split in ['train', 'val']:
        print(f"\nEnsemble {split}:")
        split_counts = Counter()
        labels_path = os.path.join(output_dir, split, 'labels')
        for label_file in os.listdir(labels_path):
            try:
                with open(os.path.join(labels_path, label_file)) as f:
                    class_id = int(f.readline().split()[0])
                    split_counts[class_id] += 1
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur lors de la lecture du label {label_file}: {str(e)}")

        for class_id in sorted(split_counts.keys()):
            print(f"Classe {class_id} ({class_folders[class_id]}): {split_counts[class_id]} exemples")

    print(f"\n‚úÖ Dataset pr√©par√© avec succ√®s!")
    print(f"‚úÖ Fichier YAML cr√©√©: {yaml_path}")

if __name__ == "__main__":
    # Configuration
    source_dir = "/content/drive/MyDrive/sli1/database"
    output_dir = "/content/drive/MyDrive/sli1/Faissal"
    min_samples = 100  # Nombre minimum d'√©chantillons par classe

    # Pr√©paration du dataset
    prepare_dataset(source_dir, output_dir, min_samples)

pip install ultralytics

pip install opencv-python

import os
import cv2
import matplotlib.pyplot as plt

# üëâ Change ce chemin par le tien !
image_folder = "/content/drive/MyDrive/sli1/Faissal/train/images"

# üì¶ Stocker toutes les dimensions
widths, heights = [], []

for filename in os.listdir(image_folder):
    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
        img_path = os.path.join(image_folder, filename)
        img = cv2.imread(img_path)
        if img is not None:
            h, w = img.shape[:2]
            widths.append(w)
            heights.append(h)

# üìà R√©sum√©
print(f"üì∑ Nombre d'images analys√©es : {len(widths)}")
print(f"üìè Taille moyenne : {int(sum(widths)/len(widths))} x {int(sum(heights)/len(heights))}")
print(f"üìâ Taille min     : {min(widths)} x {min(heights)}")
print(f"üìà Taille max     : {max(widths)} x {max(heights)}")

# üìä Distribution
plt.figure(figsize=(10,5))
plt.hist(widths, bins=30, alpha=0.6, label='Largeurs')
plt.hist(heights, bins=30, alpha=0.6, label='Hauteurs')
plt.title("Distribution des tailles d'images")
plt.xlabel("Pixels")
plt.ylabel("Nombre d'images")
plt.legend()
plt.grid(True)
plt.show()

from ultralytics import YOLO
import torch
import os
import yaml
from pathlib import Path

# Pour √©viter les erreurs li√©es √† OpenMP
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

# === CONFIGURATION ===
yaml_path = '/content/drive/MyDrive/sli1/Faissal/dataset.yaml'
model_name = 'yolov8n.pt'
project_name = 'sli_detector'

def verify_dataset(yaml_path):
    """V√©rifie la validit√© du dataset"""
    try:
        with open(yaml_path, 'r') as f:
            data = yaml.safe_load(f)

        required_keys = ['path', 'train', 'val', 'nc', 'names']
        for key in required_keys:
            if key not in data:
                raise ValueError(f"Cl√© manquante dans dataset.yaml: {key}")

        # V√©rifier l'existence des dossiers
        base_path = Path(data['path'])
        train_path = base_path / data['train']
        val_path = base_path / data['val']

        if not train_path.exists():
            raise ValueError(f"Dossier d'entra√Ænement non trouv√©: {train_path}")
        if not val_path.exists():
            raise ValueError(f"Dossier de validation non trouv√©: {val_path}")

        print("‚úÖ V√©rification du dataset r√©ussie")
        print(f"üìä Nombre de classes: {data['nc']}")
        print("üìã Classes:")
        for idx, name in enumerate(data['names']):
            print(f"   {idx}: {name}")

        return True
    except Exception as e:
        print(f"‚ùå Erreur lors de la v√©rification du dataset: {str(e)}")
        return False

def train_model(yaml_path, model_name='yolov8n.pt', project_name='sli_detector'):
    """Entra√Æne le mod√®le YOLOv8 avec les param√®tres optimis√©s"""
    print(f"‚öôÔ∏è Configuration utilis√©e:")
    print(f"   - Dataset: {yaml_path}")
    print(f"   - Mod√®le: {model_name}")
    print(f"   - Projet: {project_name}")

    # V√©rifier si GPU disponible
    device = '0' if torch.cuda.is_available() else 'cpu'
    print(f"üñ•Ô∏è Utilisation de: {'GPU' if device == '0' else 'CPU'}")

    try:
        # Chargement du mod√®le
        model = YOLO(model_name)

        # Param√®tres d'entra√Ænement optimis√©s pour la d√©tection de panneaux
        results = model.train(
            data=yaml_path,
            epochs=55,
            imgsz=720,
            batch=16,
            name=project_name,
            device=device,
            val=True,
            mosaic=0.2,
            scale=0.5,
            multi_scale=True,
            fliplr=0.2,
            hsv_h=0.015,
            hsv_s=0.6,
            hsv_v=0.4,
            copy_paste=0.0,
            mixup=0.0,
            lr0=0.01,
            lrf=0.001,
            momentum=0.937,
            weight_decay=0.0005,
            warmup_epochs=3.0,
            warmup_momentum=0.8,
            warmup_bias_lr=0.1,
            box=7.5,
            cls=0.5,
            dfl=1.5,
)

        return results, True

    except Exception as e:
        print(f"‚ùå Erreur lors de l'entra√Ænement: {str(e)}")
        return None, False

def save_training_info(results, project_name):
    """Sauvegarde les informations d'entra√Ænement"""
    try:
        output_dir = Path(f"runs/detect/{project_name}")
        info_file = output_dir / "training_info.txt"

        with open(info_file, 'w') as f:
            f.write("=== R√©sultats d'entra√Ænement ===\n")
            f.write(f"Meilleure pr√©cision (mAP50): {results.results_dict['metrics/mAP50(B)']:.4f}\n")
            f.write(f"Meilleure pr√©cision (mAP50-95): {results.results_dict['metrics/mAP50-95(B)']:.4f}\n")
            f.write(f"Epochs effectu√©es: {results.results_dict['epoch']}\n")

        print(f"‚úÖ Informations d'entra√Ænement sauvegard√©es dans: {info_file}")
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors de la sauvegarde des informations: {str(e)}")

if __name__ == "__main__":
    print("üöÄ D√©marrage de l'entra√Ænement du mod√®le YOLOv8...")

    # V√©rification du dataset
    if not verify_dataset(yaml_path):
        print("‚ùå Arr√™t de l'entra√Ænement d√ª aux erreurs dans le dataset")
        exit(1)

    # Entra√Ænement
    results, success = train_model(yaml_path, model_name, project_name)

    if success:
        print("\n‚úÖ Entra√Ænement termin√© avec succ√®s!")
        print(f"üìÅ Meilleur mod√®le sauvegard√©: runs/detect/{project_name}/weights/best.pt")

        # Sauvegarder les informations d'entra√Ænement
        if results is not None:
            save_training_info(results, project_name)
    else:
        print("‚ùå L'entra√Ænement a √©chou√©")

import os
import random
import shutil
from sklearn.model_selection import train_test_split
import yaml

# === CONFIGURATION ===
source_dir = "/content/drive/MyDrive/speed_limit_detection1/database"
output_dir = "/content/drive/MyDrive/sli1/dataset"
images_dir = os.path.join(output_dir, "images")
labels_dir = os.path.join(output_dir, "labels")

# === CLASSES SELON TON YAML ===
class_map = {
    "Speed_limit_20kmh": 0,
    "Speed_limit_30kmh": 1,
    "Speed_limit_50kmh": 2,
    "Speed_limit_60kmh": 3,
    "Speed_limit_70kmh": 4,
    "Speed_limit_80kmh": 5,
    "End_speed_limit_80": 6,
    "Speed_limit_100kmh": 7,
    "Speed_limit_120kmh": 8,
    "Speed_limit_5kmh": 9,
    "Speed_limit_15kmh": 10,
    "Speed_limit_110kmh": 11,
    "Speed_limit_90kmh": 12,
    "Speed_limit_40kmh": 13,
    "Road_work": 14,
    "End_speed_passing_limits": 15
}

# Cr√©ation des dossiers
os.makedirs(images_dir, exist_ok=True)
os.makedirs(labels_dir, exist_ok=True)

# === COPIER LES IMAGES ET CR√âER LES LABELS ===
for class_folder, class_id in class_map.items():
    class_path = os.path.join(source_dir, class_folder)
    if not os.path.exists(class_path):
        print(f"‚ö†Ô∏è Dossier non trouv√© : {class_path}")
        continue

    for filename in os.listdir(class_path):
        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
            # G√©n√©rer un nom unique en cas de doublons
            new_filename = f"{class_folder}_{filename}"
            src_path = os.path.join(class_path, filename)
            dst_img_path = os.path.join(images_dir, new_filename)
            dst_txt_path = os.path.join(labels_dir, os.path.splitext(new_filename)[0] + ".txt")

            # Copier l‚Äôimage
            shutil.copyfile(src_path, dst_img_path)

            # Cr√©er un label fictif centr√© (√† modifier apr√®s avec vraies bboxes)
            with open(dst_txt_path, 'w') as f:
                f.write(f"{class_id} 0.5 0.5 0.5 0.5\n")

# === S√âPARATION TRAIN / VAL (80/20) ===
all_images = os.listdir(images_dir)
train_imgs, val_imgs = train_test_split(all_images, test_size=0.2, random_state=42)

# Cr√©er les dossiers YOLO
for split in ['train', 'val']:
    for folder in ['images', 'labels']:
        os.makedirs(os.path.join(output_dir, split, folder), exist_ok=True)

# Copier les fichiers dans train/val
for img_list, split in [(train_imgs, 'train'), (val_imgs, 'val')]:
    for img in img_list:
        label = os.path.splitext(img)[0] + ".txt"
        shutil.copy(os.path.join(images_dir, img), os.path.join(output_dir, split, "images", img))
        shutil.copy(os.path.join(labels_dir, label), os.path.join(output_dir, split, "labels", label))

# === G√âN√âRER LE FICHIER dataset.yaml ===
dataset_yaml = {
    'path': output_dir,
    'train': 'train/images',
    'val': 'val/images',
    'nc': 16,
    'names': [
        "Speed_limit_20kmh",
        "Speed_limit_30kmh",
        "Speed_limit_50kmh",
        "Speed_limit_60kmh",
        "Speed_limit_70kmh",
        "Speed_limit_80kmh",
        "End_speed_limit_80",
        "Speed_limit_100kmh",
        "Speed_limit_120kmh",
        "Speed_limit_5kmh",
        "Speed_limit_15kmh",
        "Speed_limit_110kmh",
        "Speed_limit_90kmh",
        "Speed_limit_40kmh",
        "Road_work",
        "End_speed_passing_limits"
    ]
}

yaml_path = os.path.join(output_dir, 'dataset.yaml')
with open(yaml_path, 'w') as f:
    yaml.dump(dataset_yaml, f, sort_keys=False)

print(f"‚úÖ Dataset pr√™t !\n- Images : {images_dir}\n- Labels : {labels_dir}\n- YAML : {yaml_path}")

pip install ultralytics

import os
import shutil
import yaml
from sklearn.model_selection import train_test_split

# 1. Dossier source contenant les 16 classes (chaque dossier = une classe)
source_dir = "/content/drive/MyDrive/speed_limit_detection1/database"

# 2. Dossier de sortie
output_dir = "/content/drive/MyDrive/SLI2/dataset"
images_dir = os.path.join(output_dir, "images")
labels_dir = os.path.join(output_dir, "labels")

# 3. Nettoyage et pr√©paration
os.makedirs(images_dir, exist_ok=True)
os.makedirs(labels_dir, exist_ok=True)

# 4. Cr√©er le mapping dynamique des classes
class_folders = sorted(os.listdir(source_dir))  # ordre alphab√©tique
class_map = {folder: idx for idx, folder in enumerate(class_folders)}

print("‚úÖ Mapping des classes (automatique) :")
for name, idx in class_map.items():
    print(f"{idx}: {name}")

# 5. G√©n√©rer les images et labels
for class_name, class_id in class_map.items():
    class_path = os.path.join(source_dir, class_name)
    for filename in os.listdir(class_path):
        if filename.lower().endswith(('.jpg', '.png', '.jpeg')):
            src_img_path = os.path.join(class_path, filename)
            dst_img_path = os.path.join(images_dir, filename)
            dst_lbl_path = os.path.join(labels_dir, os.path.splitext(filename)[0] + ".txt")

            # Copier l'image
            shutil.copyfile(src_img_path, dst_img_path)

            # Cr√©er un label fictif pour chaque image (class_id au centre)
            with open(dst_lbl_path, 'w') as f:
                f.write(f"{class_id} 0.5 0.5 0.5 0.5\n")  # √† remplacer par bbox r√©elle si dispo

# 6. S√©paration train / val
all_images = os.listdir(images_dir)
train_imgs, val_imgs = train_test_split(all_images, test_size=0.2, random_state=42)

for split in ['train', 'val']:
    for folder in ['images', 'labels']:
        os.makedirs(os.path.join(output_dir, split, folder), exist_ok=True)

for img_list, split in [(train_imgs, 'train'), (val_imgs, 'val')]:
    for img in img_list:
        label = os.path.splitext(img)[0] + ".txt"
        shutil.copy(os.path.join(images_dir, img), os.path.join(output_dir, split, "images", img))
        shutil.copy(os.path.join(labels_dir, label), os.path.join(output_dir, split, "labels", label))

# 7. Cr√©ation du fichier dataset.yaml
dataset_yaml = {
    'path': output_dir,
    'train': 'train/images',
    'val': 'val/images',
    'nc': len(class_map),
    'names': [name for name in class_folders]
}

yaml_path = os.path.join(output_dir, 'dataset.yaml')
with open(yaml_path, 'w') as f:
    yaml.dump(dataset_yaml, f, sort_keys=False)

print(f"\n‚úÖ Fichier 'dataset.yaml' cr√©√© ici : {yaml_path}")

import os
import shutil
import yaml
from sklearn.model_selection import train_test_split
# 2. Dossier de sortie
source_dir = "/content/drive/MyDrive/speed_limit_detection1/database"
output_dir = "/content/drive/MyDrive/sli1/dataset"
images_dir = os.path.join(output_dir, "images")
labels_dir = os.path.join(output_dir, "labels")
class_folders = sorted(os.listdir(source_dir))
class_map = {folder: idx for idx, folder in enumerate(class_folders)}
# 7. Cr√©ation du fichier dataset.yaml
dataset_yaml = {
    'path': output_dir,
    'train': 'train/images',
    'val': 'val/images',
    'nc': len(class_map),
    'names': [name for name in class_folders]
}

yaml_path = os.path.join(output_dir, 'dataset.yaml')
with open(yaml_path, 'w') as f:
    yaml.dump(dataset_yaml, f, sort_keys=False)

print(f"\n‚úÖ Fichier 'dataset.yaml' cr√©√© ici : {yaml_path}")

from ultralytics import YOLO
import torch
import os

#  Pour √©viter les erreurs li√©es √† OpenMP
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

# === CONFIGURATION ===
#  Assure-toi que ce chemin soit accessible. Tu peux soit :
# - Mettre le fichier dataset.yaml dans Colab (/content/)
# - OU le laisser dans Drive si tu veux
yaml_path = '/content/drive/MyDrive/sli1/dataset/dataset.yaml'  #  Mets ton fichier ici via upload ou copie depuis Drive
model_name = 'yolov8n.pt'            #  Ce mod√®le sera t√©l√©charg√© automatiquement par Ultralytics
project_name = 'sli_detector'

def train_model():
    print(f" Configuration utilis√©e : {yaml_path}")

    #  Chargement automatique du mod√®le YOLOv8 nano
    #  Pas besoin de le t√©l√©charger manuellement, Ultralytics le fait pour toi
    model = YOLO(model_name)

    #  Entra√Ænement du mod√®le
    results = model.train(
        data=yaml_path,              # fichier .yaml avec les chemins vers tes images
        epochs=100,                  # nombre d‚Äô√©poques
        imgsz=640,                   # taille des images
        batch=16,                    # taille de lot
        name=project_name,           # nom du projet
        verbose=True,                # affichage des logs
        device='0' if torch.cuda.is_available() else 'cpu',  # GPU si dispo
        patience=20,                 # early stopping
        save=True,                   # sauvegarde des checkpoints
        pretrained=True,             # utilise le mod√®le pr√©-entra√Æn√©
        optimizer='auto',             # choix automatique de l‚Äôoptimiseur
        val=True,                    # forcer l'√©valuation √† chaque epoch
        seed=42                      # pour reproductibilit√©
    )

    return results

if __name__ == "__main__":
    print("==>  D√©marrage de l'entra√Ænement du mod√®le YOLOv8...")

    if not os.path.exists(yaml_path):
        print(f" ERREUR : Fichier dataset.yaml introuvable √† : {yaml_path}")
    else:
        results = train_model()
        print("\n Entra√Ænement termin√© !")
        print(f" Meilleur mod√®le sauvegard√© ici : runs/detect/{project_name}/weights/best.pt")

import os
print([f for f in os.listdir() if f.startswith("torch")])

import os
os.kill(os.getpid(), 9)

from ultralytics import YOLO
import torch
import os
import yaml
import shutil

# Fix OpenMP runtime error
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

def create_dataset_yaml(dataset_dir):
    yaml_content = {
        'path': dataset_dir,  # dataset root dir
        'train': 'train/images',  # train images
        'val': 'val/images',      # val images
        'test': 'test/images',    # test images
        'nc': 12,  # number of classes
        'names': {  # class names
            0: 'speed_limit_20',
            1: 'speed_limit_30',
            2: 'speed_limit_50',
            3: 'speed_limit_60',
            4: 'speed_limit_70',
            5: 'speed_limit_80',
            6: 'speed_limit_100',
            7: 'speed_limit_120',
            8: 'speed_limit_90',
            9: 'speed_limit_110',
            10: 'speed_limit_130',
            11: 'speed_limit_unknown'  # Add this for any unexpected classes
        }
    }
    yaml_path = os.path.join(os.path.dirname(dataset_dir), 'dataset.yaml')
    with open(yaml_path, 'w') as f:
        yaml.dump(yaml_content, f, sort_keys=False)
    print(f"Created dataset.yaml at: {yaml_path}")
    return yaml_path

def setup_dataset_structure():
    # Define base directory
    base_dir = os.path.dirname(os.path.abspath(__file__))
    dataset_dir = os.path.join(base_dir, 'dataset')

    # Create dataset directories
    dirs = [
        os.path.join(dataset_dir, 'train', 'images'),
        os.path.join(dataset_dir, 'train', 'labels'),
        os.path.join(dataset_dir, 'val', 'images'),
        os.path.join(dataset_dir, 'val', 'labels'),
        os.path.join(dataset_dir, 'test', 'images'),
        os.path.join(dataset_dir, 'test', 'labels')
    ]

    for d in dirs:
        os.makedirs(d, exist_ok=True)
        print(f"Created directory: {d}")

    return dataset_dir

def train_model():
    # Setup dataset structure
    dataset_dir = setup_dataset_structure()

    # Check if dataset directories are empty
    train_images = os.path.join(dataset_dir, 'train', 'images')
    if not os.listdir(train_images):
        print(f"Warning: Training images directory is empty: {train_images}")
        print("Please copy your dataset files to the correct directories before training.")
        return None

    # Create dataset.yaml
    yaml_path = create_dataset_yaml(dataset_dir)

    # Load a model
    model = YOLO('yolov8n.pt')  # load pretrained model

    # Train the model
    results = model.train(
        data=yaml_path,
        epochs=30,
        imgsz=640,
        batch=-1,
        name='speed_limit_detector',
        verbose=True,
        device='0' if torch.cuda.is_available() else 'cpu',
        patience=20,  # Early stopping patience
        save=True,    # Save checkpoints
        pretrained=True,
        optimizer='auto'
    )

    return results

if __name__ == "__main__":
    print("Setting up dataset structure...")
    dataset_dir = setup_dataset_structure()

    print("\nPlease ensure your dataset files are in these directories:")
    print(f"Training images: {os.path.join(dataset_dir, 'train', 'images')}")
    print(f"Training labels: {os.path.join(dataset_dir, 'train', 'labels')}")
    print(f"Validation images: {os.path.join(dataset_dir, 'val', 'images')}")
    print(f"Validation labels: {os.path.join(dataset_dir, 'val', 'labels')}")

    user_input = input("\nHave you copied your dataset files to these directories? (yes/no): ")
    if user_input.lower() == 'yes':
        print("\nStarting training...")
        results = train_model()
        if results:
            print("Training completed successfully!")
            print("Best model saved at: runs/detect/speed_limit_detector/weights/best.pt")
    else:
        print("\nPlease copy your dataset files to the correct directories and run the script again.")

"""## new test"""

pip install ultralytics

from ultralytics import YOLO
import torch
import os
import yaml
import shutil

# Fix OpenMP runtime error
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

def setup_dataset_structure():
    # Define base directory
    base_dir = '/content/drive/MyDrive/sli1'
    dataset_dir = os.path.join(base_dir, 'data_3914')

    # Create dataset directories
    dirs = [
        os.path.join(dataset_dir, 'train', 'images'),
        os.path.join(dataset_dir, 'train', 'labels'),
        os.path.join(dataset_dir, 'val', 'images'),
        os.path.join(dataset_dir, 'val', 'labels'),
        os.path.join(dataset_dir, 'test', 'images'),
        os.path.join(dataset_dir, 'test', 'labels')
    ]

    for d in dirs:
        os.makedirs(d, exist_ok=True)
        print(f"Created directory: {d}")

    return dataset_dir

def train_model():
    # Setup dataset structure
    dataset_dir = setup_dataset_structure()

    # Check if dataset directories are empty
    train_images = os.path.join(dataset_dir, 'train', 'images')
    if not os.listdir(train_images):
        print(f"Warning: Training images directory is empty: {train_images}")
        print("Please copy your dataset files to the correct directories before training.")
        return None

    # Create dataset.yaml
    yaml_path = '/content/drive/MyDrive/sli1/data_3914/data.yaml'

    # Load a model
    model = YOLO('yolov8n.pt')  # load pretrained model

    # Train the model
    results = model.train(
        data=yaml_path,
        epochs=280,
        imgsz=640,
        batch=16,
        name='speed_limit_detector',
        verbose=True,
        device='0' if torch.cuda.is_available() else 'cpu',
        patience=20,  # Early stopping patience
        save=True,    # Save checkpoints
        pretrained=True,
        optimizer='auto'
    )

    return results

if __name__ == "__main__":
    print("Setting up dataset structure...")
    dataset_dir = setup_dataset_structure()

    print("\nPlease ensure your dataset files are in these directories:")
    print(f"Training images: {os.path.join(dataset_dir, 'train', 'images')}")
    print(f"Training labels: {os.path.join(dataset_dir, 'train', 'labels')}")
    print(f"Validation images: {os.path.join(dataset_dir, 'val', 'images')}")
    print(f"Validation labels: {os.path.join(dataset_dir, 'val', 'labels')}")

    user_input = input("\nHave you copied your dataset files to these directories? (yes/no): ")
    if user_input.lower() == 'yes':
        print("\nStarting training...")
        results = train_model()
        if results:
            print("Training completed successfully!")
            print("Best model saved at: runs/detect/speed_limit_detector/weights/best.pt")
    else:
        print("\nPlease copy your dataset files to the correct directories and run the script again.")

