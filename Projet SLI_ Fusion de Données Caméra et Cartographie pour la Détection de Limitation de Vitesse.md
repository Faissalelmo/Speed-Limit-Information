# ğŸš¦ Projet SLI: Fusion de DonnÃ©es CamÃ©ra et Cartographie pour la DÃ©tection de Limitation de Vitesse

## Table des MatiÃ¨res
1. [Objectif du Projet](#objectif-du-projet)
2. [Modules UtilisÃ©s](#modules-utilisÃ©s)
3. [Structure du DÃ©pÃ´t](#structure-du-dÃ©pÃ´t)
4. [DÃ©pendances](#dÃ©pendances)
5. [Ã‰tapes pour l'ExÃ©cuter](#Ã©tapes-pour-lexÃ©cuter)
6. [RÃ©sultats et DÃ©monstrations](#rÃ©sultats-et-dÃ©monstrations)
7. [Code Complet et Datasets](#code-complet-et-datasets)

## 1. Objectif du Projet
Ce projet de fin d'Ã©tudes vise Ã  amÃ©liorer la fiabilitÃ© de la dÃ©tection des limitations de vitesse dans les vÃ©hicules en combinant deux sources dâ€™information : la dÃ©tection visuelle par camÃ©ra et les donnÃ©es issues de la cartographie numÃ©rique. Le systÃ¨me dÃ©veloppÃ© repose sur une architecture modulaire, intÃ©grant des algorithmes de vision embarquÃ©e, de map-matching, et de fusion dÃ©cisionnelle. Lâ€™approche proposÃ©e permet de pallier les limites de chaque mÃ©thode lorsquâ€™elles sont utilisÃ©es de maniÃ¨re isolÃ©e, en assurant une meilleure prÃ©cision et une meilleure couverture dans la dÃ©tection des vitesses maximales autorisÃ©es. L'objectif est d'atteindre une fiabilitÃ© supÃ©rieure Ã  97% pour le systÃ¨me SLI (Speed Limit Information).

## 2. Modules UtilisÃ©s
Le projet est structurÃ© autour de plusieurs modules principaux, chacun ayant un rÃ´le spÃ©cifique dans le processus de dÃ©tection et de fusion des donnÃ©es de limitation de vitesse:

*   **`camera_detection`**: Contient le code et les modÃ¨les liÃ©s Ã  la dÃ©tection des panneaux de signalisation par vision par ordinateur (YOLOv8).
*   **`map_detection`**: GÃ¨re l'acquisition, le traitement et le recalage des donnÃ©es cartographiques (OpenStreetMap, OSRM) et GPS.
*   **`fusion_algorithm`**: ImplÃ©mente l'algorithme de fusion des donnÃ©es provenant de la camÃ©ra et de la carte pour une estimation fiable de la limitation de vitesse.
*   **`common_utils`**: Regroupe les utilitaires et fonctions partagÃ©es par les diffÃ©rents modules.

## 3. Structure du DÃ©pÃ´t
```
. 
â”œâ”€â”€ camera_detection/
â”‚   â”œâ”€â”€ yolov8_model/           # ModÃ¨les YOLOv8 entraÃ®nÃ©s et configurations
â”‚   â”œâ”€â”€ scripts/                # Scripts pour l'infÃ©rence et le traitement vidÃ©o
â”‚   â””â”€â”€ data_preparation/       # Scripts pour la prÃ©paration des datasets (annotation, augmentation)
â”œâ”€â”€ map_data_processing/
â”‚   â”œâ”€â”€ osrm_integration/       # Code pour l'intÃ©gration avec OSRM (Map-Matching)
â”‚   â”œâ”€â”€ osm_data/               # Gestion des donnÃ©es OpenStreetMap (tÃ©lÃ©chargement, stockage)
â”‚   â””â”€â”€ gps_processing/         # Traitement des donnÃ©es GPS brutes
â”œâ”€â”€ fusion_algorithm/           # Algorithmes de fusion et logique dÃ©cisionnelle
â”œâ”€â”€ common_utils/               # Fonctions utilitaires partagÃ©es
â”œâ”€â”€ data_and_models/            # Emplacement pour les datasets bruts, modÃ¨les prÃ©-entraÃ®nÃ©s, etc.
â”œâ”€â”€ docs/                       # Documentation additionnelle, rapports, prÃ©sentations
â”œâ”€â”€ results/                    # Images et vidÃ©os des rÃ©sultats de dÃ©tection et de fusion
â”œâ”€â”€ README.md                   # Ce fichier
â”œâ”€â”€ requirements.txt            # Liste des dÃ©pendances Python
â””â”€â”€ .gitignore                  # Fichier pour ignorer les fichiers non nÃ©cessaires dans Git
```

## 4. DÃ©pendances
Ce projet nÃ©cessite les dÃ©pendances Python suivantes. Il est recommandÃ© de crÃ©er un environnement virtuel pour les installer:

```bash
pip install -r requirements.txt
```

Les principales bibliothÃ¨ques utilisÃ©es incluent:
*   `ultralytics` (pour YOLOv8)
*   `opencv-python`
*   `Pillow`
*   `numpy`
*   `pandas`
*   `geopandas`
*   `shapely`
*   `folium`
*   `PyQt5` (pour l'interface graphique)
*   `python-can` (pour la simulation CAN)
*   `requests` (pour les requÃªtes API)
*   `python-dotenv`
*   `gpxpy`
*   `scikit-learn`
*   `matplotlib`
*   `seaborn`

Pour le module de traitement cartographique, OSRM doit Ãªtre exÃ©cutÃ© localement, idÃ©alement via Docker. Les instructions pour sa mise en place sont dÃ©taillÃ©es dans le `map_data_processing/README.md`.

## 5. Ã‰tapes pour l'ExÃ©cuter

### 5.1. Configuration de l'Environnement
1.  **Cloner le dÃ©pÃ´t GitHub**:
    ```bash
    git clone [URL_DU_DEPOT]
    cd [NOM_DU_DEPOT]
    ```
2.  **CrÃ©er et activer un environnement virtuel** (recommandÃ©):
    ```bash
    python -m venv venv
    source venv/bin/activate  # Linux/macOS
    # ou
    .\venv\Scripts\activate   # Windows
    ```
3.  **Installer les dÃ©pendances Python**:
    ```bash
    pip install -r requirements.txt
    ```
4.  **Mettre en place OSRM (via Docker)**:
    Suivez les instructions dans `map_data_processing/README.md` pour lancer le serveur OSRM localement.

### 5.2. PrÃ©paration des DonnÃ©es et ModÃ¨les
*   **ModÃ¨les YOLOv8**: Les modÃ¨les prÃ©-entraÃ®nÃ©s ou vos propres modÃ¨les entraÃ®nÃ©s doivent Ãªtre placÃ©s dans `camera_detection/yolov8_model/`.
*   **DonnÃ©es OSM**: Le systÃ¨me tÃ©lÃ©chargera automatiquement les donnÃ©es OSM nÃ©cessaires via l'API Overpass. Assurez-vous d'avoir une connexion internet fonctionnelle lors de la premiÃ¨re exÃ©cution.
*   **Traces GPS**: Placez vos fichiers `.gpx` de traces GPS dans `map_data_processing/gps_processing/`.

### 5.3. ExÃ©cution du Projet
Le projet est conÃ§u pour Ãªtre exÃ©cutÃ© via un script principal qui orchestre les diffÃ©rents modules. Des exemples de scripts d'exÃ©cution seront fournis dans les dossiers de chaque module.

*   **ExÃ©cution du module de dÃ©tection camÃ©ra**:
    ```bash
    python camera_detection/scripts/run_detection.py 
    ```
*   **ExÃ©cution du module de traitement cartographique**:
    ```bash
    python map_data_processing/run_map_processing.py 
    ```
*   **ExÃ©cution du systÃ¨me de fusion**:
    ```bash
    python fusion_algorithm/run_fusion.py
    ```

Des paramÃ¨tres supplÃ©mentaires peuvent Ãªtre spÃ©cifiÃ©s (voir les `README.md` spÃ©cifiques Ã  chaque module pour plus de dÃ©tails).

## 6. RÃ©sultats et DÃ©monstrations
Ce dossier contient des images et des vidÃ©os illustrant les rÃ©sultats obtenus lors des tests du projet. Vous y trouverez des exemples de:

*   DÃ©tection de panneaux de signalisation en temps rÃ©el par YOLOv8.
*   Visualisation du recalage cartographique (Map-Matching) des traces GPS sur OpenStreetMap.
*   DÃ©monstrations de la fusion des donnÃ©es camÃ©ra et carte, et de l'affichage des limitations de vitesse.

**AccÃ©der aux rÃ©sultats**: [[Lien vers le dossier `results](https://drive.google.com/drive/folders/1RfBbEmmLGVCvTwhYuqfYjoiG9TB6Wwa_?usp=drive_link)]

## 7. Code Complet et Datasets
Le code complet du projet, incluant les datasets d'entraÃ®nement, les notebooks Jupyter, et les scripts dÃ©taillÃ©s, est disponible dans le dossier Google Drive suivant:

ğŸ‘‰ [**[Le lien vers le projet SLI](https://drive.google.com/drive/folders/1oTisFENqo5xwP31eMjg7Vhcya6iwTsfb?usp=drive_link)**]

Ce lien vous donnera accÃ¨s Ã  l'intÃ©gralitÃ© des ressources du projet, y compris les donnÃ©es brutes et les modÃ¨les spÃ©cifiques.

## ğŸ“Š Features

- âœ… Real-time detection of speed limit signs
- âœ… GUI with PyQt5
- âœ… Distance estimation between sign and camera
- âœ… Speed quality alert
- âœ… Works on webcam or video input

## ğŸ”® Future Improvements

- Integrate vehicle's real speed from GPS or CAN bus
- Add voice alerts for over-speeding
- Expand to detect other traffic signs (Stop, Yield, etc.)
- Deploy on edge devices (Jetson Nano, Raspberry Pi)

## ğŸ‘¤ Author

Developed by **Faissal Elmokaddem**  
ğŸ“§ Contact: faissal.elmokaddem@gmail.com  
ğŸ”— LinkedIn: [linkedin.com/in/faissal-elmokaddem](https://linkedin.com/in/faissal-elmokaddem)  
ğŸ’» GitHub: [github.com/FaissalElmokaddem](https://github.com/FaissalElmokaddem)

## ğŸ“œ License

This project is licensed under the MIT License.

---

ğŸš— *"Driving safely with AI-powered vision."*
